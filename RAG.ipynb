{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bac5472",
   "metadata": {},
   "source": [
    "## Policy Document Indexing for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c2a6a7",
   "metadata": {},
   "source": [
    "We start by creating the following functions: ```clean_text``` & ```load_files```. When looking at the given pdfs, we observe that the pdf is clean. There is no number of pages, images any extra context that should be removed. However we create a function that would lower the text, removes multiple spaces, etc. We decided not to get rid of punctions as they seem to be relevant. When it comes to the function ```load_files```, we assume that in the future the folder will be filled with other file extensions as well. Thus we create a generic function that would look at pdfs and other extensions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d35916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielazemencikova/Desktop/capstone/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded & cleaned tuition-reimbursement-policy.pdf\n",
      "Loaded & cleaned health-insurance-policy.pdf\n",
      "Loaded & cleaned work-from-home-policy.pdf\n",
      "Loaded & cleaned gym-policy.pdf\n",
      "Loaded & cleaned vacation-policy.pdf\n",
      "Loaded & cleaned 401k-retirement-policy.pdf\n",
      "Loaded & cleaned life-insurance-policy.pdf\n",
      "Loaded & cleaned childcare-policy.pdf\n",
      "\n",
      "Total loaded documents: 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "from langchain_community.document_loaders import TextLoader, Docx2txtLoader, CSVLoader\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Path to the documents\n",
    "dir_path = 'assets/documents/'\n",
    "\n",
    "# -------------------------------\n",
    "# Text cleaning function\n",
    "# -------------------------------\n",
    "# Function to clean and remove noise from text\n",
    "# We observe that the pdfs don't contain any page numbers, or images\n",
    "def clean_text(text: str, lowercase: bool = True, remove_punct: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Cleans extracted text for preprocessing:\n",
    "    - Lowercase (optional)\n",
    "    - Remove line breaks, tabs\n",
    "    - Remove punctuation (optional)\n",
    "    - Normalize spaces\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "\n",
    "    # Replace newlines and tabs with space \n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "    \n",
    "    if remove_punct:\n",
    "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# -------------------------------\n",
    "# File loader\n",
    "# -------------------------------\n",
    "def load_files(path: str) -> list[Document]:\n",
    "    _, file_extension = os.path.splitext(path)\n",
    "    file_extension = file_extension.lower()\n",
    "\n",
    "    if file_extension == '.pdf':\n",
    "        reader = PdfReader(path)\n",
    "        all_text = \"\".join((p.extract_text() or \"\") for p in reader.pages)\n",
    "        cleaned = clean_text(all_text, lowercase=True, remove_punct=False)\n",
    "        return [Document(page_content=cleaned, metadata={\"source\": path})]\n",
    "\n",
    "    elif file_extension == '.txt':\n",
    "        docs = TextLoader(path, encoding='utf8').load()\n",
    "        for d in docs:\n",
    "            d.page_content = clean_text(d.page_content)\n",
    "        return docs\n",
    "\n",
    "    elif file_extension == '.docx':\n",
    "        docs = Docx2txtLoader(path).load()\n",
    "        for d in docs:\n",
    "            d.page_content = clean_text(d.page_content)\n",
    "        return docs\n",
    "        \n",
    "    elif file_extension == '.csv':\n",
    "        docs = CSVLoader(path).load()\n",
    "        for d in docs:\n",
    "            d.page_content = clean_text(d.page_content)\n",
    "        return docs\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Usage example\n",
    "# -------------------------------\n",
    "files = [f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))]\n",
    "\n",
    "# Collect all loaded documents\n",
    "all_documents = []\n",
    "for filename in files:\n",
    "    full_path = os.path.join(dir_path, filename)\n",
    "    try:\n",
    "        docs = load_files(full_path)\n",
    "        all_documents.extend(docs)\n",
    "        print(f\"Loaded & cleaned {filename}\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "\n",
    "print(f\"\\nTotal loaded documents: {len(all_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd5768f",
   "metadata": {},
   "source": [
    "After loading and cleaning the documents, we split them into chunks. Firstly, we tried a function that would split the documents into section, to have another source of metadata - to refet to the document and a specific section, however if there are documents which have sections that are very long, that doesn't seem like a proper option. So we use ```RecursiveCharacterTextSplitter``` wuth chunk_overlap to keep the context between chunks and not lose meaning.\n",
    "\n",
    "Afterwards, we define a function ```create_chroma_collection``` that would create a vector store using openai embeddings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c99c1842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original docs: 8\n",
      "Split docs: 146\n",
      "\n",
      "--- Chunk 1 ---\n",
      "techlance tuition reimbursement policy introduction techlance is committed to supporting the professional growth and career development of our employees through comprehensive educational assistance programs. we believe that investing in our team members’ education not only enhances their skills and  ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "--- Chunk 2 ---\n",
      "to accommodate working professionals who want to advance their education while maintaining their career momentum. whether you’re pursuing your ﬁrst degree, advancing to graduate studies, or seeking professional certiﬁcations to enhance your expertise, techlance is here to support your educational jo ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3s/sgsxmx5n0nv1mqxxx0w71rn40000gn/T/ipykernel_27429/1599929069.py:44: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection created and persisted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3s/sgsxmx5n0nv1mqxxx0w71rn40000gn/T/ipykernel_27429/1599929069.py:53: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  collection.persist()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We start by splitting the document into sections for later text preprocessing\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Suppose `documents` is what you loaded from load_files()\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,    # max characters per chunk\n",
    "    chunk_overlap=200,  # overlap between chunks (keeps context)\n",
    ")\n",
    "\n",
    "split_docs = splitter.split_documents(all_documents)\n",
    "\n",
    "print(f\"Original docs: {len(all_documents)}\")\n",
    "print(f\"Split docs: {len(split_docs)}\")\n",
    "\n",
    "# Show first 2 chunks\n",
    "for i, d in enumerate(split_docs[:2], 1):\n",
    "    print(f\"\\n--- Chunk {i} ---\")\n",
    "    print(d.page_content[:300], \"...\")\n",
    "    print(\"Metadata:\", d.metadata)\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Create a new Chroma collection & split documents into chunks\n",
    "def create_chroma_collection(\n",
    "    name: str, \n",
    "    documents: List[Document], \n",
    "    directory: str\n",
    ") -> Chroma:\n",
    "    \"\"\"\n",
    "    Create or overwrite a Chroma collection with given documents.\n",
    "\n",
    "    Args:\n",
    "        name (str): Name of the collection.\n",
    "        documents (List[Document]): List of LangChain Document objects.\n",
    "        directory (str): Directory where the collection is persisted.\n",
    "\n",
    "    Returns:\n",
    "        Chroma: The created Chroma vectorstore.\n",
    "    \"\"\"\n",
    "    persist_directory = os.path.join(directory, name)\n",
    "    os.makedirs(persist_directory, exist_ok=True)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    # Create collection and persist it\n",
    "    collection = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        collection_name=name,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    collection.persist()\n",
    "    return collection\n",
    "\n",
    "collection = create_chroma_collection(\n",
    "    name=\"benefits_collection\",\n",
    "    documents=split_docs,\n",
    "    directory=\"./persist\"\n",
    ")\n",
    "\n",
    "print(\"Collection created and persisted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75693b82",
   "metadata": {},
   "source": [
    "Last functions to be created are ```load_chroma_collection```, ```add_documents_to_collection``` and ```load_retriever_from_collection```. \n",
    "\n",
    "With adding documents to the collection we use incremental updates. New PDFs, DOCX files, or CSVs may arrive over time. Instead of rebuilding the entire collection from scratch, we can add only the new documents. This saves time and computation, especially for large collections. Preserve embeddings for existing docs. Lastly, we can aggregate multiple new documents and add them in one go, improving efficiency.\n",
    "\n",
    "```load_retriever_from_collection``` helps not to recreate the existing vectorstore when restarting the script. The function had configurable retrieval parameters, where we can set things like score_threshold, search_type, or top_k when loading the retriever. This allows us to tune retrieval behavior without changing the underlying vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8047089",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the collection\n",
    "def load_chroma_collection(name: str, directory: str) -> Chroma:\n",
    "    \"\"\"\n",
    "    Load an existing Chroma collection.\n",
    "\n",
    "    Args:\n",
    "        name (str): Name of the collection.\n",
    "        directory (str): Directory where the collection is persisted.\n",
    "\n",
    "    Returns:\n",
    "        Chroma: The loaded Chroma vectorstore.\n",
    "    \"\"\"\n",
    "    persist_directory = os.path.join(directory, name)\n",
    "    if not os.path.exists(persist_directory):\n",
    "        raise ValueError(f\"Collection '{name}' does not exist in '{directory}'.\")\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    collection = Chroma(\n",
    "        collection_name=name,\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    return collection\n",
    "\n",
    "# Add documents to the collection\n",
    "def add_documents_to_collection(collection: Chroma, new_documents: List[Document]) -> None:\n",
    "    \"\"\"\n",
    "    Add new documents to an existing Chroma collection.\n",
    "\n",
    "    Args:\n",
    "        collection (Chroma): The Chroma vectorstore to add documents to.\n",
    "        new_documents (List[Document]): List of new LangChain Document objects to add.\n",
    "    \"\"\"\n",
    "    if not new_documents:\n",
    "        print(\"No new documents to add.\")\n",
    "        return\n",
    "\n",
    "    collection.add_documents(new_documents)\n",
    "    collection.persist()\n",
    "    print(f\"Added {len(new_documents)} documents to the collection and persisted changes.\")\n",
    "    \n",
    "# Load retriever from the collection\n",
    "def load_retriever_from_collection(\n",
    "    collection_name: str,\n",
    "    search_type: str = \"similarity_score_threshold\",\n",
    "    score_threshold: float = 0.3,\n",
    "    top_k: int = 5\n",
    "):\n",
    "    \"\"\"\n",
    "    Load a retriever from a Chroma collection with configurable retrieval behavior.\n",
    "\n",
    "    Args:\n",
    "        collection_name (str): Name of the Chroma collection.\n",
    "        search_type (str): Retrieval type (similarity_score_threshold or mmr).\n",
    "        score_threshold (float): Minimum similarity score for retrieval.\n",
    "        top_k (int): Number of documents to return.\n",
    "\n",
    "    Returns:\n",
    "        Retriever: Configured retriever.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the persisted collection\n",
    "    collection = load_chroma_collection(name=collection_name, directory=\"./persist\")\n",
    "    \n",
    "    # Build retriever with configurable behavior\n",
    "    retriever = collection.as_retriever(\n",
    "        search_type=search_type,\n",
    "        search_kwargs={\n",
    "            \"score_threshold\": score_threshold,\n",
    "            \"k\": top_k\n",
    "        }\n",
    "    )\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8351d1c1",
   "metadata": {},
   "source": [
    "Example of dynamically storing documents:\n",
    "The script will run only if there is a new file to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf8bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3s/sgsxmx5n0nv1mqxxx0w71rn40000gn/T/ipykernel_27429/1497834706.py:19: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  collection = Chroma(\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'assets/new_policy.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m new_files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massets/new_policy.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m new_files:\n\u001b[0;32m----> 8\u001b[0m     new_docs\u001b[38;5;241m.\u001b[39mextend(\u001b[43mload_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Add to collection\u001b[39;00m\n\u001b[1;32m     11\u001b[0m add_documents_to_collection(collection, new_docs)\n",
      "Cell \u001b[0;32mIn[1], line 55\u001b[0m, in \u001b[0;36mload_files\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     52\u001b[0m file_extension \u001b[38;5;241m=\u001b[39m file_extension\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_extension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 55\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43mPdfReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     all_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((p\u001b[38;5;241m.\u001b[39mextract_text() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mpages)\n\u001b[1;32m     57\u001b[0m     cleaned \u001b[38;5;241m=\u001b[39m clean_text(all_text, lowercase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, remove_punct\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/capstone/.venv/lib/python3.9/site-packages/PyPDF2/_reader.py:317\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[0;34m(self, stream, strict, password)\u001b[0m\n\u001b[1;32m    311\u001b[0m     logger_warning(\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPdfReader stream/file object is not in binary mode. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt may not be read correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    315\u001b[0m     )\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    318\u001b[0m         stream \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(stream)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'assets/new_policy.pdf'"
     ]
    }
   ],
   "source": [
    "# # Load existing collection\n",
    "# collection = load_chroma_collection(\"benefits_collection\", \"./persist\")\n",
    "\n",
    "# # Load new PDFs\n",
    "# new_docs = []\n",
    "# new_files = [\"assets/new_policy.pdf\"]\n",
    "# for f in new_files:\n",
    "#     new_docs.extend(load_files(f))\n",
    "\n",
    "# # Add to collection\n",
    "# add_documents_to_collection(collection, new_docs)\n",
    "\n",
    "# print(\"Collection updated with new documents!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "624f69d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Query: What's the maternity leave policy?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3s/sgsxmx5n0nv1mqxxx0w71rn40000gn/T/ipykernel_27429/3195497748.py:15: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found 3 results\n",
      "\n",
      "--- Result 1 ---\n",
      "of paid maternity leave, while non-birth parents receive six weeks of paid paternity leave. adoptive parents receive eight weeks of paid leave that can be shared between both parents. employees must have been with the company for at least 12 months to qualify for paid parental leave, though unpaid l ...\n",
      "Metadata: {'source': 'assets/documents/childcare-policy.pdf'}\n",
      "\n",
      "--- Result 2 ---\n",
      "for ﬁnding specialized care providers in the community. this policy is eﬀective as of [current date] and may be modiﬁed as business needs and legal requirements change. employees will receive 30 days advance notice of any signiﬁcant changes to childcare beneﬁts. for speciﬁc questions about your situ ...\n",
      "Metadata: {'source': 'assets/documents/childcare-policy.pdf'}\n",
      "\n",
      "--- Result 3 ---\n",
      "launch periods, and other critical business periods that will be communicated to employees at least 60 days in advance. while we try to minimize blackout periods, these restrictions help ensure we can meet our commitments to clients and stakeholders during crucial times. year-end and carryover polic ...\n",
      "Metadata: {'source': 'assets/documents/vacation-policy.pdf'}\n",
      "\n",
      "\n",
      "Query: What is the eligibility for Tuition Reimbursement\n",
      " Found 3 results\n",
      "\n",
      "--- Result 1 ---\n",
      "standards to be eligible for tuition reimbursement, employees must have completed at least 12 months of continuous full-time employment or 18 months of part-time employment (minimum 20 hours per week). this tenure requirement ensures that employees have established themselves in their roles and demo ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "--- Result 2 ---\n",
      "to accommodate working professionals who want to advance their education while maintaining their career momentum. whether you’re pursuing your ﬁrst degree, advancing to graduate studies, or seeking professional certiﬁcations to enhance your expertise, techlance is here to support your educational jo ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "--- Result 3 ---\n",
      "separate check. reimbursements may be subject to income tax depending on irs regulations and the total amount received during the tax year. we recommend consulting with a tax professional if you have questions about the tax implications of educational reimbursements. service commitments and repaymen ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "\n",
      "Query: How much can employees contribute to 401-k?\n",
      " Found 3 results\n",
      "\n",
      "--- Result 1 ---\n",
      "50 and older can make additional “catch-up” contributions of $7,500 annually in 2024, allowing total contributions of up to $30,500. these catch-up contributions help employees who may have started saving for retirement later in their careers or who want to accelerate their savings as they approach  ...\n",
      "Metadata: {'source': 'assets/documents/401k-retirement-policy.pdf'}\n",
      "\n",
      "--- Result 2 ---\n",
      "accelerates your retirement savings, making it essential to contribute at least enough to receive the full company match. our matching contributions are subject to a vesting schedule that encourages long-term employment while protecting the company’s investment in your retirement. you’re always 100% ...\n",
      "Metadata: {'source': 'assets/documents/401k-retirement-policy.pdf'}\n",
      "\n",
      "--- Result 3 ---\n",
      "and professionally managed investment options, you can create a solid foundation for retirement security while focusing on your career and current ﬁnancial needs. we believe that retirement planning should be a partnership between you and techlance, which is why we contribute signiﬁcantly to your re ...\n",
      "Metadata: {'source': 'assets/documents/401k-retirement-policy.pdf'}\n",
      "\n",
      "\n",
      "Query: Do I have to manually enroll for 401-k?\n",
      " Found 3 results\n",
      "\n",
      "--- Result 1 ---\n",
      "signiﬁcant company matching and establishes good savings habits from the beginning. if you prefer not to participate in the 401(k) plan, you can opt out during your ﬁrst 90 days and receive a refund of any contributions made. however, we strongly encourage participation since the combination of tax  ...\n",
      "Metadata: {'source': 'assets/documents/401k-retirement-policy.pdf'}\n",
      "\n",
      "--- Result 2 ---\n",
      "are designed to help you build substantial retirement savings without requiring constant attention or diﬃcult decisions. research shows that employees who participate in automatic enrollment and escalation typically accumulate signiﬁcantly more retirement wealth than those who don’t, even when contr ...\n",
      "Metadata: {'source': 'assets/documents/401k-retirement-policy.pdf'}\n",
      "\n",
      "--- Result 3 ---\n",
      "accelerates your retirement savings, making it essential to contribute at least enough to receive the full company match. our matching contributions are subject to a vesting schedule that encourages long-term employment while protecting the company’s investment in your retirement. you’re always 100% ...\n",
      "Metadata: {'source': 'assets/documents/401k-retirement-policy.pdf'}\n",
      "\n",
      "\n",
      "Query: I work in Finance, can I work remotely?\n",
      " Found 3 results\n",
      "\n",
      "--- Result 1 ---\n",
      "everyone involved. frequently asked questionscan i work from home occasionally without a formal remote work agreement? yes, you can work remotely up to two days per month with manager approval and advance notice for situations like appointments, weather issues, or home repairs. what happens if my in ...\n",
      "Metadata: {'source': 'assets/documents/work-from-home-policy.pdf'}\n",
      "\n",
      "--- Result 2 ---\n",
      "and oﬀers reimbursement allowances for ergonomic improvements, internet service, and oﬃce supplies. you’re responsible for basic furniture and utilities. what if my manager doesn’t approve my remote work request? managers must provide speciﬁc business reasons for denial. you can discuss concerns wit ...\n",
      "Metadata: {'source': 'assets/documents/work-from-home-policy.pdf'}\n",
      "\n",
      "--- Result 3 ---\n",
      "home oﬃce to protect company information. what happens if my performance declines while working remotely? your manager will work with you to identify issues and create an improvement plan, which may include additional support, training, or temporarily returning to on-site work. this policy is eﬀecti ...\n",
      "Metadata: {'source': 'assets/documents/work-from-home-policy.pdf'}\n"
     ]
    }
   ],
   "source": [
    "retriever = load_retriever_from_collection(\"benefits_collection\", score_threshold = 0.6, top_k=3)\n",
    "\n",
    "\n",
    "queries = [\n",
    "    \"What's the maternity leave policy?\",\n",
    "    \"What is the eligibility for Tuition Reimbursement\",\n",
    "    \"How much can employees contribute to 401-k?\",\n",
    "    \"Do I have to manually enroll for 401-k?\",\n",
    "    \"I work in Finance, can I work remotely?\"\n",
    "]\n",
    "\n",
    "for i in queries:\n",
    "    print(f\"\\n\\nQuery: {i}\")\n",
    "    query = i\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "\n",
    "    print(f\" Found {len(results)} results\")\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"\\n--- Result {i} ---\")\n",
    "        print(r.page_content[:300], \"...\")\n",
    "        print(\"Metadata:\", r.metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6518571c",
   "metadata": {},
   "source": [
    "## Try different types of retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e478f",
   "metadata": {},
   "source": [
    "Different similarity score threshold, mmr, top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f20c54a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Retrieval config: {'search_type': 'similarity_score_threshold', 'score_threshold': 0.3, 'top_k': 3} ---\n",
      "\n",
      "Query: What's the maternity leave policy?\n",
      "\n",
      "Result 1:\n",
      "of paid maternity leave, while non-birth parents receive six weeks of paid paternity leave. adoptive parents receive eight weeks of paid leave that can be shared between both parents. employees must have been with the company for at least 12 months to qualify for paid parental leave, though unpaid l ...\n",
      "Metadata: {'source': 'assets/documents/childcare-policy.pdf'}\n",
      "\n",
      "Result 2:\n",
      "for ﬁnding specialized care providers in the community. this policy is eﬀective as of [current date] and may be modiﬁed as business needs and legal requirements change. employees will receive 30 days advance notice of any signiﬁcant changes to childcare beneﬁts. for speciﬁc questions about your situ ...\n",
      "Metadata: {'source': 'assets/documents/childcare-policy.pdf'}\n",
      "\n",
      "Result 3:\n",
      "launch periods, and other critical business periods that will be communicated to employees at least 60 days in advance. while we try to minimize blackout periods, these restrictions help ensure we can meet our commitments to clients and stakeholders during crucial times. year-end and carryover polic ...\n",
      "Metadata: {'source': 'assets/documents/vacation-policy.pdf'}\n",
      "\n",
      "Query: What is the eligibility for Tuition Reimbursement\n",
      "\n",
      "Result 1:\n",
      "standards to be eligible for tuition reimbursement, employees must have completed at least 12 months of continuous full-time employment or 18 months of part-time employment (minimum 20 hours per week). this tenure requirement ensures that employees have established themselves in their roles and demo ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "Result 2:\n",
      "to accommodate working professionals who want to advance their education while maintaining their career momentum. whether you’re pursuing your ﬁrst degree, advancing to graduate studies, or seeking professional certiﬁcations to enhance your expertise, techlance is here to support your educational jo ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "Result 3:\n",
      "separate check. reimbursements may be subject to income tax depending on irs regulations and the total amount received during the tax year. we recommend consulting with a tax professional if you have questions about the tax implications of educational reimbursements. service commitments and repaymen ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "--- Retrieval config: {'search_type': 'similarity_score_threshold', 'score_threshold': 0.5, 'top_k': 3} ---\n",
      "\n",
      "Query: What's the maternity leave policy?\n",
      "\n",
      "Result 1:\n",
      "of paid maternity leave, while non-birth parents receive six weeks of paid paternity leave. adoptive parents receive eight weeks of paid leave that can be shared between both parents. employees must have been with the company for at least 12 months to qualify for paid parental leave, though unpaid l ...\n",
      "Metadata: {'source': 'assets/documents/childcare-policy.pdf'}\n",
      "\n",
      "Result 2:\n",
      "for ﬁnding specialized care providers in the community. this policy is eﬀective as of [current date] and may be modiﬁed as business needs and legal requirements change. employees will receive 30 days advance notice of any signiﬁcant changes to childcare beneﬁts. for speciﬁc questions about your situ ...\n",
      "Metadata: {'source': 'assets/documents/childcare-policy.pdf'}\n",
      "\n",
      "Result 3:\n",
      "launch periods, and other critical business periods that will be communicated to employees at least 60 days in advance. while we try to minimize blackout periods, these restrictions help ensure we can meet our commitments to clients and stakeholders during crucial times. year-end and carryover polic ...\n",
      "Metadata: {'source': 'assets/documents/vacation-policy.pdf'}\n",
      "\n",
      "Query: What is the eligibility for Tuition Reimbursement\n",
      "\n",
      "Result 1:\n",
      "standards to be eligible for tuition reimbursement, employees must have completed at least 12 months of continuous full-time employment or 18 months of part-time employment (minimum 20 hours per week). this tenure requirement ensures that employees have established themselves in their roles and demo ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "Result 2:\n",
      "to accommodate working professionals who want to advance their education while maintaining their career momentum. whether you’re pursuing your ﬁrst degree, advancing to graduate studies, or seeking professional certiﬁcations to enhance your expertise, techlance is here to support your educational jo ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "Result 3:\n",
      "separate check. reimbursements may be subject to income tax depending on irs regulations and the total amount received during the tax year. we recommend consulting with a tax professional if you have questions about the tax implications of educational reimbursements. service commitments and repaymen ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "--- Retrieval config: {'search_type': 'mmr', 'top_k': 5} ---\n",
      "\n",
      "Query: What's the maternity leave policy?\n",
      "\n",
      "Result 1:\n",
      "of paid maternity leave, while non-birth parents receive six weeks of paid paternity leave. adoptive parents receive eight weeks of paid leave that can be shared between both parents. employees must have been with the company for at least 12 months to qualify for paid parental leave, though unpaid l ...\n",
      "Metadata: {'source': 'assets/documents/childcare-policy.pdf'}\n",
      "\n",
      "Result 2:\n",
      "launch periods, and other critical business periods that will be communicated to employees at least 60 days in advance. while we try to minimize blackout periods, these restrictions help ensure we can meet our commitments to clients and stakeholders during crucial times. year-end and carryover polic ...\n",
      "Metadata: {'source': 'assets/documents/vacation-policy.pdf'}\n",
      "\n",
      "Result 3:\n",
      "techlance childcare support policy introduction techlance understands that balancing career responsibilities with family obligations can be challenging, particularly for employees with young children. we believe that providing comprehensive childcare support not only helps our team members achieve b ...\n",
      "Metadata: {'source': 'assets/documents/childcare-policy.pdf'}\n",
      "\n",
      "Result 4:\n",
      "6:30 pm. we recommend arranging for an authorized contact to pick up your child, or using our backup care services for extended days. are there childcare options if i travel for work? our backup care network may have options in other cities, and you can use the emergency childcare fund for travel-re ...\n",
      "Metadata: {'source': 'assets/documents/childcare-policy.pdf'}\n",
      "\n",
      "Result 5:\n",
      "in insurance oﬀerings, legal requirements, or business needs. employees will receive advance notice of any signiﬁcant changes. for questions about your speciﬁc coverage or beneﬁts, contact hr or call the customer service number on your insurance card. ...\n",
      "Metadata: {'source': 'assets/documents/health-insurance-policy.pdf'}\n",
      "\n",
      "Query: What is the eligibility for Tuition Reimbursement\n",
      "\n",
      "Result 1:\n",
      "standards to be eligible for tuition reimbursement, employees must have completed at least 12 months of continuous full-time employment or 18 months of part-time employment (minimum 20 hours per week). this tenure requirement ensures that employees have established themselves in their roles and demo ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "Result 2:\n",
      "your direct manager ﬁrst evaluates the job relevance and scheduling implications, followed by hr veriﬁcation of eligibility and policy compliance. for reimbursement amounts over $3,000, senior management approval is required. the ﬁnance team conﬁrms budget availability before ﬁnal approval is grante ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "Result 3:\n",
      "graduate-level courses. pass/fail courses require a “pass” grade, and professional certiﬁcations require successful completion and achievement of the certiﬁcation or license. you must submit oﬃcial transcripts within 60 days of course completion along with receipts and proof of payment for all cover ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "Result 4:\n",
      "however, this doesn’t automatically disqualify you from future educational assistance. can i pursue multiple certiﬁcations in the same year? yes, but you’re limited to the annual maximum reimbursement amount for your category of education. consider spreading certiﬁcations across multiple calendar ye ...\n",
      "Metadata: {'source': 'assets/documents/tuition-reimbursement-policy.pdf'}\n",
      "\n",
      "Result 5:\n",
      "veriﬁcation. the program covers expenses for daycare centers, family daycare homes, preschools, after-schoolprograms, and summer camps. it does not typically cover informal care arrangements such as unlicensed babysitters or care provided by family members unless they operate a licensed childcare bu ...\n",
      "Metadata: {'source': 'assets/documents/childcare-policy.pdf'}\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"What's the maternity leave policy?\",\n",
    "    \"What is the eligibility for Tuition Reimbursement\"\n",
    "]\n",
    "\n",
    "# Define different retrieval configurations\n",
    "retrieval_configs = [\n",
    "    {\"search_type\": \"similarity_score_threshold\", \"score_threshold\": 0.3, \"top_k\": 3},\n",
    "    {\"search_type\": \"similarity_score_threshold\", \"score_threshold\": 0.5, \"top_k\": 3},\n",
    "    {\"search_type\": \"mmr\", \"top_k\": 5}\n",
    "]\n",
    "\n",
    "for config in retrieval_configs:\n",
    "    print(f\"\\n--- Retrieval config: {config} ---\")\n",
    "    retriever = load_retriever_from_collection(\n",
    "        collection_name=\"benefits_collection\",\n",
    "        search_type=config.get(\"search_type\", \"similarity_score_threshold\"),\n",
    "        score_threshold=config.get(\"score_threshold\", 0.3),\n",
    "        top_k=config.get(\"top_k\", 5)\n",
    "    )\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        for i, doc in enumerate(docs, 1):\n",
    "            print(f\"\\nResult {i}:\")\n",
    "            print(doc.page_content[:300], \"...\")\n",
    "            print(\"Metadata:\", doc.metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481f0b1",
   "metadata": {},
   "source": [
    "## Advanced RAG Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fdc76a",
   "metadata": {},
   "source": [
    "### Metadata Filtering \n",
    "\n",
    "Useful if we want to use only specific files for our answers. It is useful if we had different departments and they had different documents or different years. It all depends what metadata we can collect and what would be useful. In this case we only store different files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a337bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_retriever_from_collection(\n",
    "    collection_name: str,\n",
    "    search_type: str = \"similarity_score_threshold\",\n",
    "    score_threshold: float = 0.3,\n",
    "    top_k: int = 5,\n",
    "    metadata_filter: dict = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Load a retriever from a Chroma collection with configurable retrieval behavior\n",
    "    and optional metadata filtering.\n",
    "\n",
    "    Args:\n",
    "        collection_name (str): Name of the Chroma collection.\n",
    "        search_type (str): Retrieval type (\"similarity_score_threshold\" or \"mmr\").\n",
    "        score_threshold (float): Minimum similarity score for retrieval.\n",
    "        top_k (int): Number of documents to return.\n",
    "        metadata_filter (dict): Optional filter, e.g. {\"source\": \"assets/documents/vacation-policy.pdf\"}\n",
    "\n",
    "    Returns:\n",
    "        Retriever: Configured retriever.\n",
    "    \"\"\"\n",
    "    collection = load_chroma_collection(name=collection_name, directory=\"./persist\")\n",
    "    \n",
    "    retriever = collection.as_retriever(\n",
    "        search_type=search_type,\n",
    "        search_kwargs={\n",
    "            \"score_threshold\": score_threshold,\n",
    "            \"k\": top_k,\n",
    "            \"filter\": metadata_filter  # <-- apply metadata filter\n",
    "        }\n",
    "    )\n",
    "    return retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb8243",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df93778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: How long ahead do I need to request vacation for longer than 4 days?\n",
      "\n",
      "Result 1:\n",
      "and approval process we ask that employees provide advance notice when requesting vacation time to ensure adequate coverage and minimize disruption to team projects and client commitments. for short absences of one to two days, we require at least one week of advance notice. requests for three to fo ...\n",
      "Metadata: {'source': 'assets/documents/vacation-policy.pdf'}\n",
      "\n",
      "Result 2:\n",
      "feedbackand business needs. how far in advance can i schedule vacation time? there’s no limit on how far in advance you can request vacation, though we recommend not scheduling more than a year ahead to allow for potential changes in business needs or personal circumstances. what if i need more time ...\n",
      "Metadata: {'source': 'assets/documents/vacation-policy.pdf'}\n",
      "\n",
      "Result 3:\n",
      "scheduled time oﬀ before approving. once approved by your manager, hr will conﬁrm that you have suﬃcient vacation balance available, and you’ll receive email conﬁrmation of your approved time oﬀ. vacation time can be taken in increments as small as four hours (half day), and there’s no minimum amoun ...\n",
      "Metadata: {'source': 'assets/documents/vacation-policy.pdf'}\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"How long ahead do I need to request vacation for longer than 4 days?\"\n",
    "]\n",
    "\n",
    "# Example: Only search documents from vacation policy folder\n",
    "metadata_filter = {\"source\": \"assets/documents/vacation-policy.pdf\"}  \n",
    "\n",
    "retriever = load_retriever_from_collection(\n",
    "    collection_name=\"benefits_collection\",\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    score_threshold=0.3,\n",
    "    top_k=3,\n",
    "    metadata_filter=metadata_filter\n",
    ")\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        print(f\"\\nResult {i}:\")\n",
    "        print(doc.page_content[:300], \"...\")\n",
    "        print(\"Metadata:\", doc.metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e23db46",
   "metadata": {},
   "source": [
    "### Query expansion \n",
    "\n",
    "Automatically expand your query with related terms to improve retrieval. The disadvantage is LLM-generated expansions cost API calls, however if we pregenarate expansions that could be useful however it requires domain knowledge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f6b59a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded terms: ['1. Parental leave guidelines', '2. Family leave policy', '3. Maternal leave rules', '4. Childbirth leave provisions', '5. Maternity leave regulations']\n",
      "\n",
      "Result 1:\n",
      "from the emergency childcare fund for occasional oﬀ-hours needs.eligibility and enrollment all full-time employees working 30 or more hours per week are eligible for our complete range of childcare beneﬁts. part-time employees working at least 20 hours per week qualify for on-site childcare, fsa ben ...\n",
      "\n",
      "Result 2:\n",
      "that any advanced time will be reconciled through future accruals or payroll deduction if employment ends before the time is earned. we also provide ﬂoating holidays speciﬁcally for religious and cultural observances that may not align with our standard company holidays. each employee receives two ﬂ ...\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI \n",
    "client = OpenAI() \n",
    "\n",
    "def expand_query(query: str, n_terms: int = 5) -> list[str]: \n",
    "    \"\"\" Use LLM to generate related terms for query expansion. \"\"\" \n",
    "    prompt = f\"\"\" \n",
    "        Generate {n_terms} synonyms of the core word/phrase of the following query for use in document retrieval. \n",
    "        Keep them short, noun-phrases. Query: \"{query}\" \"\"\" \n",
    "    \n",
    "    response = client.chat.completions.create( model=\"gpt-4o-mini\", messages=[{\"role\":\"user\",\"content\": prompt}], max_tokens=100 ) \n",
    "    text = response.choices[0].message.content.strip() \n",
    "    \n",
    "    return [t.strip(\"-• \") for t in text.split(\"\\n\") if t.strip()] \n",
    "\n",
    "query = \"Maternity leave policy\"\n",
    "\n",
    "# 1. Generate expansions\n",
    "exp_terms = expand_query(query, n_terms=5)\n",
    "print(\"Expanded terms:\", exp_terms)\n",
    "\n",
    "# 2. Use expanded terms in retrieval\n",
    "all_queries = [query] + exp_terms\n",
    "results = []\n",
    "\n",
    "# Create a retriever\n",
    "retriever = collection.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.3, \"k\": 5}\n",
    ")\n",
    "\n",
    "for q in all_queries:\n",
    "    docs = retriever.get_relevant_documents(q)\n",
    "    results.extend(docs)\n",
    "\n",
    "# 3. Deduplicate and display\n",
    "unique_docs = {d.metadata[\"source\"]: d for d in results}.values()\n",
    "for i, doc in enumerate(unique_docs, 1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(doc.page_content[:300], \"...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "833a9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_expanded_queries(\n",
    "    collection_name: str,\n",
    "    queries: List[str],\n",
    "    search_type: str = \"similarity_score_threshold\",\n",
    "    score_threshold: float = 0.3,\n",
    "    top_k: int = 5,\n",
    "    metadata_filter: dict = None\n",
    ") -> List[Document]:\n",
    "    \"\"\"\n",
    "    Retrieve relevant documents from a Chroma collection using one or more expanded queries.\n",
    "\n",
    "    Args:\n",
    "        collection_name (str): Name of the Chroma collection.\n",
    "        queries (List[str]): List of queries, e.g., original query + expanded terms.\n",
    "        search_type (str): Retrieval type (\"similarity_score_threshold\" or \"mmr\").\n",
    "        score_threshold (float): Minimum similarity score.\n",
    "        top_k (int): Number of documents to return per query.\n",
    "        metadata_filter (dict): Optional metadata filter.\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: Aggregated, deduplicated documents.\n",
    "    \"\"\"\n",
    "    retriever = load_retriever_from_collection(\n",
    "        collection_name=collection_name,\n",
    "        search_type=search_type,\n",
    "        score_threshold=score_threshold,\n",
    "        top_k=top_k,\n",
    "        metadata_filter=metadata_filter\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    for q in queries:\n",
    "        docs = retriever.get_relevant_documents(q)\n",
    "        results.extend(docs)\n",
    "    \n",
    "    # Deduplicate by source or content\n",
    "    unique_results = {d.metadata.get(\"source\", d.page_content): d for d in results}\n",
    "    return list(unique_results.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16c59468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1:\n",
      "6:30 pm. we recommend arranging for an authorized contact to pick up your child, or using our backup care services for extended days. are there childcare options if i travel for work? our backup care network may have options in other cities, and you can use the emergency childcare fund for travel-re ...\n",
      "Metadata: {'source': 'assets/documents/childcare-policy.pdf'}\n",
      "\n",
      "Result 2:\n",
      "that any advanced time will be reconciled through future accruals or payroll deduction if employment ends before the time is earned. we also provide ﬂoating holidays speciﬁcally for religious and cultural observances that may not align with our standard company holidays. each employee receives two ﬂ ...\n",
      "Metadata: {'source': 'assets/documents/vacation-policy.pdf'}\n"
     ]
    }
   ],
   "source": [
    "query = \"Maternity leave policy\"\n",
    "expanded_terms = expand_query(query, n_terms=3)\n",
    "all_queries = [query] + expanded_terms\n",
    "\n",
    "docs = retrieve_with_expanded_queries(\n",
    "    collection_name=\"benefits_collection\",\n",
    "    queries=all_queries,\n",
    "    score_threshold=0.3,\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(doc.page_content[:300], \"...\")\n",
    "    print(\"Metadata:\", doc.metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6a3ca",
   "metadata": {},
   "source": [
    "### HyDE - Generate a “hypothetical answer” \n",
    "\n",
    "for the query, then retrieve documents closest to that answer. It is useful when the queries are short or ambiguous: If \"Maternity leave policy\" is too short, the vector search might miss relevant docs. It is useful for semantic retrieval in dense embeddings collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4bef634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothetical answer generated by LLM:\n",
      "A maternity leave policy typically outlines the amount of time off and benefits available to employees who are expecting or have recently given birth.\n",
      "\n",
      "Result 1:\n",
      "of paid maternity leave, while non-birth parents receive six weeks of paid paternity leave. adoptive parents receive eight weeks of paid leave that can be shared between both parents. employees must h ...\n",
      "\n",
      "Result 2:\n",
      "for ﬁnding specialized care providers in the community. this policy is eﬀective as of [current date] and may be modiﬁed as business needs and legal requirements change. employees will receive 30 days  ...\n",
      "\n",
      "Result 3:\n",
      "launch periods, and other critical business periods that will be communicated to employees at least 60 days in advance. while we try to minimize blackout periods, these restrictions help ensure we can ...\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "query = \"Maternity leave policy\"\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Step 1: Generate hypothetical answer\n",
    "prompt = f\"Generate a concise hypothetical answer to this question: '{query}'\"\n",
    "hypothetical_answer = llm.predict(prompt)\n",
    "\n",
    "# Print the hypothetical answer\n",
    "print(\"Hypothetical answer generated by LLM:\")\n",
    "print(hypothetical_answer)\n",
    "\n",
    "# Step 2: Retrieve documents using embedding of the hypothetical answer\n",
    "embedding_fn = OpenAIEmbeddings()\n",
    "hypothetical_vector = embedding_fn.embed_query(hypothetical_answer)\n",
    "\n",
    "# 3. Retrieve relevant documents directly from Chroma using the vector\n",
    "retriever = load_chroma_collection(\"benefits_collection\", \"./persist\")\n",
    "docs = retriever.similarity_search_by_vector(hypothetical_vector, k=3)\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"\\nResult {i}:\") \n",
    "    print(doc.page_content[:200], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419446cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
